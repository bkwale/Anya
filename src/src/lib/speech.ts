/**
 * speech.ts — Text-to-speech with cloned voice support.
 *
 * Priority:
 *  1. Pre-generated cloned voice audio (public/audio/{id}.mp3)
 *  2. Web Speech API fallback (browser TTS)
 *
 * The cloned audio files are generated by scripts/generate-voice.mjs
 * and bundled as static assets in the PWA.
 */

import { primeAudio } from "./audio";

/**
 * Map a prompt's display text back to its ID for audio file lookup.
 * Built at module load from the phrases data.
 */
const textToIdMap = new Map<string, string>();

// Lazy-loaded — populated on first call to speak()
let mapInitialised = false;

async function ensureMap() {
  if (mapInitialised) return;
  mapInitialised = true;
  try {
    // Dynamic import to avoid circular dependency
    const { allModules } = await import("./data");
    for (const mod of allModules) {
      for (const p of mod.prompts) {
        // Normalise: strip em-dashes used in warm-up display text
        const clean = p.text.replace(/\s*—\s*/g, " ... ");
        textToIdMap.set(clean, p.id);
        textToIdMap.set(p.text, p.id);
      }
    }
  } catch {
    // If data import fails, we'll fall back to browser TTS
  }
}

/**
 * Check if a cloned audio file exists for a given prompt ID.
 * Uses a HEAD request (fast, no download).
 */
async function hasClonedAudio(promptId: string): Promise<string | null> {
  const url = `${import.meta.env.BASE_URL}audio/${promptId}.mp3`;
  try {
    const res = await fetch(url, { method: "HEAD" });
    return res.ok ? url : null;
  } catch {
    return null;
  }
}

/**
 * Play a cloned voice audio file.
 */
function playClonedAudio(url: string): Promise<void> {
  return new Promise((resolve, reject) => {
    const audio = new Audio(url);
    audio.setAttribute("playsinline", "");

    audio.onended = () => resolve();
    audio.onerror = () => reject(new Error("Cloned audio playback failed"));

    audio.play().catch(reject);
  });
}

/**
 * Speak a phrase — tries cloned voice first, falls back to browser TTS.
 */
export async function speak(text: string, rate = 0.85): Promise<void> {
  // Prime audio context (iOS)
  primeAudio();

  // Try cloned voice
  await ensureMap();
  const promptId = textToIdMap.get(text);

  if (promptId) {
    const audioUrl = await hasClonedAudio(promptId);
    if (audioUrl) {
      try {
        await playClonedAudio(audioUrl);
        return; // Success — cloned voice played
      } catch {
        // Fall through to browser TTS
      }
    }
  }

  // Fallback: browser TTS
  return speakWithBrowserTTS(text, rate);
}

/**
 * Browser TTS fallback.
 */
function speakWithBrowserTTS(text: string, rate: number): Promise<void> {
  return new Promise((resolve, reject) => {
    if (!("speechSynthesis" in window)) {
      reject(new Error("Speech synthesis not supported"));
      return;
    }

    window.speechSynthesis.cancel();

    const utterance = new SpeechSynthesisUtterance(text);
    utterance.rate = rate;
    utterance.pitch = 1;
    utterance.lang = "en-GB";

    const voices = window.speechSynthesis.getVoices();
    const preferred =
      voices.find(
        (v) => v.lang.startsWith("en") && v.name.toLowerCase().includes("female"),
      ) ??
      voices.find((v) => v.lang.startsWith("en-GB")) ??
      voices.find((v) => v.lang.startsWith("en"));

    if (preferred) utterance.voice = preferred;

    utterance.onend = () => resolve();
    utterance.onerror = (e) => {
      if (e.error === "interrupted") resolve();
      else reject(e);
    };

    window.speechSynthesis.speak(utterance);
  });
}

/**
 * Preload voices (some browsers load them async).
 */
export function preloadVoices(): Promise<SpeechSynthesisVoice[]> {
  return new Promise((resolve) => {
    const voices = window.speechSynthesis.getVoices();
    if (voices.length > 0) {
      resolve(voices);
      return;
    }
    window.speechSynthesis.onvoiceschanged = () => {
      resolve(window.speechSynthesis.getVoices());
    };
  });
}
